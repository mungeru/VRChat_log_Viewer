"""
VRChat ãƒ­ã‚°ãƒ“ãƒ¥ãƒ¼ã‚¢ãƒ¼ - ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°

ãƒ•ã‚¡ã‚¤ãƒ«æ“ä½œã€ãƒ‘ãƒ¼ã‚¹å‡¦ç†ã€ã‚°ãƒ«ãƒ¼ãƒ—åˆ¤å®šãªã©ã®å…±é€šå‡¦ç†
"""

import re
import hashlib
from pathlib import Path
from typing import List, Optional, Tuple
from models import LogInfo, NotificationData
from constants import (
    ENCODINGS,
    LOG_TIMESTAMP_PATTERN,
    NOTIFICATION_PATTERN,
    DEFAULT_GROUP_NAMES,
    LONG_LINE_THRESHOLD
)


class FileUtils:
    """ãƒ•ã‚¡ã‚¤ãƒ«æ“ä½œã«é–¢ã™ã‚‹ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£"""
    
    @staticmethod
    def read_file_with_encoding(file_path: Path, progress_callback=None) -> str:
        """è¤‡æ•°ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã§è©¦è¡Œã—ã¦ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€"""
        last_error = None
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºã‚’ç¢ºèª
        file_size = file_path.stat().st_size
        
        # UTF-8ãªã©ã®ä¸€èˆ¬çš„ãªã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã§è©¦è¡Œ
        for encoding in ENCODINGS:
            try:
                # å¤§ããªãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ>5MBï¼‰ã®å ´åˆã¯ãƒãƒ£ãƒ³ã‚¯èª­ã¿è¾¼ã¿
                if file_size > 5 * 1024 * 1024 and progress_callback:
                    content_parts = []
                    chunk_size = 1024 * 1024  # 1MB chunks
                    
                    with open(file_path, 'r', encoding=encoding, errors='replace') as f:
                        while True:
                            chunk = f.read(chunk_size)
                            if not chunk:
                                break
                            content_parts.append(chunk)
                            if progress_callback:
                                progress_callback()
                    
                    return ''.join(content_parts)
                else:
                    with open(file_path, 'r', encoding=encoding, errors='replace') as f:
                        return f.read()
            except Exception as e:
                last_error = e
                continue
        
        # æœ€çµ‚æ‰‹æ®µï¼šãƒã‚¤ãƒŠãƒªãƒ¢ãƒ¼ãƒ‰ã§èª­ã¿è¾¼ã¿
        try:
            with open(file_path, 'rb') as f:
                binary_content = f.read()
            return binary_content.decode('utf-8', errors='replace')
        except Exception as e:
            raise IOError(
                f"ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ:\n\n{file_path.name}\n\n"
                f"ã‚¨ãƒ©ãƒ¼: {e}\nå‰å›ã®ã‚¨ãƒ©ãƒ¼: {last_error}"
            )
    
    @staticmethod
    def get_sorted_log_files(log_path: Path) -> List[Path]:
        """ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚½ãƒ¼ãƒˆã—ã¦å–å¾—"""
        return sorted(
            [f for f in log_path.glob("output_log_*.txt")],
            key=lambda x: x.stat().st_mtime,
            reverse=True
        )


class LogParser:
    """ãƒ­ã‚°ãƒ‘ãƒ¼ã‚¹å‡¦ç†ã«é–¢ã™ã‚‹ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£"""
    
    @staticmethod
    def parse_log_line(line: str, collapse_long_lines: bool = True) -> LogInfo:
        """ãƒ­ã‚°è¡Œã‚’è§£æ"""
        timestamp_match = re.match(LOG_TIMESTAMP_PATTERN, line)
        
        if timestamp_match:
            timestamp = timestamp_match.group(1)
            level = timestamp_match.group(2)
            content = timestamp_match.group(3).strip()
        else:
            timestamp = ""
            level = ""
            content = line.strip()
        
        # ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«ã«å¿œã˜ãŸã‚¿ã‚°
        tags = LogParser._determine_tags(line)
        
        # é•·ã„è¡Œã®æŠ˜ã‚ŠãŸãŸã¿
        if collapse_long_lines and len(content) > LONG_LINE_THRESHOLD:
            collapsed_content = content[:LONG_LINE_THRESHOLD] + "... [ã‚¯ãƒªãƒƒã‚¯ã§å±•é–‹]"
            is_collapsed = True
            full_content = content
        else:
            collapsed_content = content
            is_collapsed = False
            full_content = None
        
        return LogInfo(
            timestamp=timestamp,
            level=level,
            content=collapsed_content,
            full_content=full_content,
            is_collapsed=is_collapsed,
            tags=tags
        )
    
    @staticmethod
    def _determine_tags(line: str) -> List[str]:
        """ãƒ­ã‚°è¡Œã‹ã‚‰ã‚¿ã‚°ã‚’åˆ¤å®š"""
        tags = []
        line_lower = line.lower()
        
        if 'Received Notification' in line:
            tags.append('notification')
        elif 'error' in line_lower or 'exception' in line_lower:
            tags.append('error')
        elif 'warning' in line_lower:
            tags.append('warning')
        elif 'debug' in line_lower:
            tags.append('debug')
        elif 'info' in line_lower:
            tags.append('info')
        
        return tags
    
    @staticmethod
    def should_show_log(line: str, show_filters: dict) -> bool:
        """ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã«åŸºã¥ã„ã¦è¡¨ç¤ºã™ã‚‹ã‹åˆ¤å®š"""
        line_lower = line.lower()
        
        if not show_filters.get('error', True) and ('error' in line_lower or 'exception' in line_lower):
            return False
        if not show_filters.get('warning', True) and 'warning' in line_lower:
            return False
        if not show_filters.get('debug', True) and 'debug' in line_lower:
            return False
        if not show_filters.get('info', True) and 'info' in line_lower:
            return False
        
        return True


class NotificationParser:
    """é€šçŸ¥ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ãƒ‘ãƒ¼ã‚¹å‡¦ç†ã«é–¢ã™ã‚‹ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£"""
    
    @staticmethod
    def parse_notifications(content: str) -> List[NotificationData]:
        """é€šçŸ¥ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è§£æã—ã¦æŠ½å‡º"""
        notifications = []
        
        matches = re.findall(NOTIFICATION_PATTERN, content, re.DOTALL)
        
        if not matches:
            print("ã‚°ãƒ«ãƒ¼ãƒ—ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            return notifications
        
        success_count = 0
        error_count = 0
        
        for date_str, notif_id, created_at, message in matches:
            try:
                # ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—æ–‡å­—ã‚’å‡¦ç†
                message = NotificationParser._unescape_message(message)
                
                if not message or message.strip() == "":
                    continue
                
                group_id = GroupUtils.get_group_id_from_message(message)
                
                notif_data = NotificationData(
                    id=notif_id,
                    date=date_str,
                    created_at=created_at,
                    message=message,
                    group_id=group_id,
                    raw_line=f"{date_str} - {notif_id}"
                )
                
                notifications.append(notif_data)
                success_count += 1
                
            except Exception as e:
                error_count += 1
                print(f"é€šçŸ¥ã®è§£æã‚¨ãƒ©ãƒ¼ ({notif_id}): {e}")
                continue
        
        if success_count > 0:
            print(f"ã‚°ãƒ«ãƒ¼ãƒ—ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æŠ½å‡ºå®Œäº†: {success_count} ä»¶æˆåŠŸ, {error_count} ä»¶å¤±æ•—")
        
        return notifications
    
    @staticmethod
    def _unescape_message(message: str) -> str:
        """ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—æ–‡å­—ã‚’å‡¦ç†"""
        message = message.replace('\\n', '\n')
        message = message.replace('\\t', '\t')
        message = message.replace('\\r', '')
        message = message.replace('\\"', '"')
        return message


class GroupUtils:
    """ã‚°ãƒ«ãƒ¼ãƒ—ç®¡ç†ã«é–¢ã™ã‚‹ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£"""
    
    @staticmethod
    def get_group_id_from_message(message: str) -> str:
        """ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å†…å®¹ã‹ã‚‰ã‚°ãƒ«ãƒ¼ãƒ—IDã‚’åˆ¤å®š"""
        if 'éœ‡åº¦' in message or 'åœ°éœ‡' in message:
            return 'group_earthquake'
        elif 'å¼€åº—' in message or 'é–‹åº—' in message or 'Bar' in message or 'NBB' in message:
            return 'group_bar'
        elif 'å…¬ä¼š' in message or 'ã‚®ãƒ«ãƒ‰' in message:
            return 'group_guild'
        elif 'è§‚å…‰' in message or 'è¦³å…‰' in message:
            return 'group_tourism'
        elif 'èŒä¸š' in message or 'Achievement' in message:
            return 'group_game'
        elif 'æ‘' in message and ('é–‹' in message or 'å¼€' in message):
            return 'group_village'
        else:
            # ãã®ä»–ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¯å…ˆé ­20æ–‡å­—ã®ãƒãƒƒã‚·ãƒ¥ã§ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
            prefix = message[:20] if len(message) > 20 else message
            group_hash = hashlib.md5(prefix.encode()).hexdigest()[:8]
            return f'group_other_{group_hash}'
    
    @staticmethod
    def get_default_group_name(group_id: str) -> str:
        """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ã‚°ãƒ«ãƒ¼ãƒ—åã‚’å–å¾—"""
        return DEFAULT_GROUP_NAMES.get(group_id, f'ğŸ“Œ ãã®ä»– ({group_id[-8:]})')
    
    @staticmethod
    def organize_notifications_by_group(
        notifications: List[NotificationData],
        group_names: dict
    ) -> dict:
        """é€šçŸ¥ã‚’ã‚°ãƒ«ãƒ¼ãƒ—ã”ã¨ã«æ•´ç†"""
        groups = {}
        
        for notif in notifications:
            group_id = notif.group_id
            
            if group_id not in groups:
                groups[group_id] = {
                    'id': group_id,
                    'name': group_names.get(
                        group_id,
                        GroupUtils.get_default_group_name(group_id)
                    ),
                    'messages': []
                }
            
            groups[group_id]['messages'].append(notif)
        
        return groups


class ExportUtils:
    """ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå‡¦ç†ã«é–¢ã™ã‚‹ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£"""
    
    @staticmethod
    def export_to_json(groups: dict, messages: List[NotificationData]) -> dict:
        """JSONå½¢å¼ã§ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆç”¨ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ"""
        return {
            'groups': {
                gid: {
                    'name': ginfo['name'],
                    'message_count': len(ginfo['messages'])
                } for gid, ginfo in groups.items()
            },
            'messages': [m.to_dict() for m in messages]
        }
    
    @staticmethod
    def export_to_text(groups: dict, messages: List[NotificationData]) -> str:
        """ãƒ†ã‚­ã‚¹ãƒˆå½¢å¼ã§ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆç”¨ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ"""
        lines = []
        
        for group_id, group_info in sorted(
            groups.items(),
            key=lambda x: len(x[1]['messages']),
            reverse=True
        ):
            group_messages = [m for m in messages if m.group_id == group_id]
            if group_messages:
                lines.append(f"\n{'='*70}")
                lines.append(f"ã‚°ãƒ«ãƒ¼ãƒ—: {group_info['name']} ({len(group_messages)} ä»¶)")
                lines.append(f"{'='*70}\n")
                
                for notif in sorted(group_messages, key=lambda x: x.date):
                    lines.append(f"å—ä¿¡æ—¥æ™‚: {notif.date}")
                    lines.append(f"ä½œæˆæ—¥æ™‚: {notif.created_at}")
                    lines.append(f"ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸:\n{notif.message}")
                    lines.append(f"{'-'*70}\n")
        
        return '\n'.join(lines)
